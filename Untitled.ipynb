{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c015785a",
   "metadata": {},
   "source": [
    "## Project 1: Data import and cleaning for the use case of agricultural production and weather data of goods in Portugal\n",
    "\n",
    "The data of agricultural good production is published from the national institute of statistics in Portugal and can be accessed through their website (http://www.ine.pt). The data was collected during the period of 1986-2021 in nine different geographic locations (PT (total), Continente, Norte, Centro, Lisboa, Alentejo, Algarve, Acores, Madeira). Dimension used: data reference period, geographic location and species. Value metric is kg/ha.\n",
    "\n",
    "The data of weather recording is taken from the Portuguese Institute of the Sea and Atmosphere (IPMA) from 16 different weather stations. Climatological stations have started recording on different dates, but they all collected the minimum temperature, the maximum temperature and the precipitation variability. The excels sheets also contain meta information about each weather station."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79320140",
   "metadata": {},
   "source": [
    "### 0. Notebook preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1168e1b",
   "metadata": {},
   "source": [
    "#### Import needed libraries for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1978c48",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "print('You are using Pandas version', pd.__version__, '!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feaba9f",
   "metadata": {},
   "source": [
    "### 1. Data import of production data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25958254",
   "metadata": {},
   "source": [
    "#### Read-in production data with the correct header (year and product). Drop first row (unit metric) and last column (empty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91559a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "production_data = pd.read_csv('ine_principais_culturas_agricolas.csv', sep = ';', header = [4,6], nrows = 12, encoding = 'latin_1')\n",
    "production_data = production_data.drop(labels = 0 ,axis = 0)\n",
    "production_data = production_data.iloc[:,:-1]\n",
    "production_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b34cdd",
   "metadata": {},
   "source": [
    "#### Extract region index and region name from first column, and set the row index to the specific region index. The region name may be used for mapping the region, but will be deleted after preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641946c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_Index_and_Name = [i.split(':') for i in production_data.iloc[:,0]]\n",
    "region_Index = [i[0] for i in region_Index_and_Name]\n",
    "region_Name = [i[1] for i in region_Index_and_Name]\n",
    "production_data.index = region_Index\n",
    "production_data.iloc[:,0] = region_Name\n",
    "production_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba2419",
   "metadata": {},
   "source": [
    "#### Clean up column index and add as a new MultiIndex (Year and Product)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdf6360",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_index_year = production_data.columns.get_level_values(0).to_series()\n",
    "column_index_year  = column_index_year.mask(column_index_year.apply(lambda i: i.startswith('Unnamed'))).ffill()\n",
    "column_index_year[0] = \"\"\n",
    "column_index_product = production_data.columns.get_level_values(1).to_series()\n",
    "column_index_product[0] = \"\"\n",
    "production_data.columns = pd.MultiIndex.from_arrays([column_index_year,column_index_product], names=('year', 'Product') )\n",
    "production_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b4bbf7",
   "metadata": {},
   "source": [
    "#### First look at some descriptive statistics of the data. We see, that some products have missing values and that all products have at max 9 unique values (possibly some rows are the same). Therefore, some data cleaning is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ca91cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c0d0b2",
   "metadata": {},
   "source": [
    "### 2. Data cleaning of production data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6c6a4d",
   "metadata": {},
   "source": [
    "#### In the dataframe of the production data, we found 3 types of unclean data values:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ed6271",
   "metadata": {},
   "source": [
    "#### First, there are provisional values (marked with '&'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66957ac2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "production_data[\"2021\"][\"Vinha\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14be32a1",
   "metadata": {},
   "source": [
    "#### Second, some values were not available (marked with 'x x'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ecd13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "production_data[\"1986\"][\"Uva para vinho (IGP)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbba6c9",
   "metadata": {},
   "source": [
    "#### And third, there are values that are null or not applicable (marked with '- -'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7af544",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_data[\"2021\"][\"Trigo duro\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b67c6c",
   "metadata": {},
   "source": [
    "#### To also compute the provisional values, we remove the '&' and use them as normal values. The null values should be replaced by 0, the values that were not available with NaN. As all three cases contain a space, we can search for 'space' and split the string into two parts. Take the first part as new value. After that we can replace '-' with 0, change values back to integer and replace 'x' with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86defc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(production_data.columns)):\n",
    "    production_data.iloc[:,i] = production_data.iloc[:,i].astype(str).str.split(\" \").str[0]\n",
    "    \n",
    "production_data.replace('-', 0, inplace = True)\n",
    "production_data.replace('x', -999, inplace = True)\n",
    "production_data.iloc[:,1:] = production_data.iloc[:,1:].astype(int)\n",
    "production_data.replace(-999, 'NaN', inplace = True)\n",
    "\n",
    "production_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2fa090",
   "metadata": {},
   "source": [
    "#### After data cleaning, we can look again at some descriptive statistics. Now we obtain sample statistics for the mean, standard deviation and the range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6866bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21b1942",
   "metadata": {},
   "source": [
    "#### To do a first graphical visualization, try a first plot of the production data. For example, plot the produced amount of 4 products in year 2021 for every region. We see, that especially table grape had high production values in Alentejo and Algarve in 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d425e7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(production_data[\"2021\"]['Cereais para grão'], label = \"Cereais para grão\")\n",
    "plt.plot(production_data[\"2021\"]['Trigo'], label = \"Trigo\")\n",
    "plt.plot(production_data[\"2021\"]['Aveia'], label = \"Aveia\")\n",
    "plt.plot(production_data[\"2021\"]['Uva de mesa'], label = \"Uva de mesa\")\n",
    "\n",
    "plt.title('Produced Amount of example products')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Amount kg/ha')\n",
    "legend = plt.legend(loc='upper right', shadow=True, fontsize='x-small')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c4dbd9",
   "metadata": {},
   "source": [
    "#### To make a combination with the weather data and accessibility easier, we change the dataframe structure to have the region and years as row index and the product as column index. Bring the wide format to a long format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378c5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_data = production_data.iloc[:,1:].stack(0)\n",
    "production_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91080be",
   "metadata": {},
   "source": [
    "#### Now we can get each data for a region in long format, just by addressing the region index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeb0676",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_data.loc['PT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e7458",
   "metadata": {},
   "source": [
    "### 2. Data import of weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed83751b",
   "metadata": {},
   "source": [
    "#### Import the weather data from all excel sheets. Each sheet contains a table for meta info, min temperature, max temperature and precipitation. First we extract the filenames that are in the local folder (workingdirectory\\\\IPMA). In this way we can automate the import even if new excel sheets for other stations are added to that folder. From the file name, we can extract the station identificator, as the sheets are labeled beginning with the station id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc1f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.getcwd()\n",
    "data_path=file_path+'\\\\'+'IPMA'\n",
    "file_names=[\".\".join(f.split(\".\")[:-1]) for f in listdir(data_path) if isfile (join(data_path,f))] \n",
    "full_file_names=[f for f in listdir(data_path) if isfile (join(data_path,f))]\n",
    "\n",
    "tmin_names = []\n",
    "tmax_names = []\n",
    "prec_names = []\n",
    "meta_names = []\n",
    "station_names = []\n",
    "for i in range(len(full_file_names)):\n",
    "    tmin_names.append('tmin_station_'+full_file_names[i].split(\"-\")[0]) \n",
    "    tmax_names.append('tmax_station_'+full_file_names[i].split(\"-\")[0]) \n",
    "    prec_names.append('prec_station_'+full_file_names[i].split(\"-\")[0])\n",
    "    meta_names.append('meta_station_'+full_file_names[i].split(\"-\")[0])\n",
    "    station_names.append('station_'+full_file_names[i].split(\"-\")[0])\n",
    "\n",
    "print('The following excel sheets are in the local folder:',full_file_names)\n",
    "print()\n",
    "print('Therefore', len(full_file_names), 'data sheets about the stations with names', station_names, 'will be imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19101904",
   "metadata": {},
   "source": [
    "#### Now the needed tables are imported for all stations and all sheets (meta, tmin, tmax, prec). The data is combined into one dataframe for each station, that can be addressed by station_'staion number'. Additionally all rows are dropped, where there is no value for each month. And the column index for December is overwritten, as the coding is different for the temperature sheets and precipitation (Dez != Dec)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a8a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=0\n",
    "files_ready=[]\n",
    "\n",
    "for mi, ma, prec, meta, r, s in zip(tmin_names, tmax_names, prec_names, meta_names, full_file_names, station_names):\n",
    "    globals()[mi]=pd.read_excel(data_path+'\\\\'+r, sheet_name = 'tmin', usecols = range(0,13))\n",
    "    globals()[ma]=pd.read_excel(data_path+'\\\\'+r, sheet_name = 'tmax', usecols = range(0,13))\n",
    "    globals()[prec]=pd.read_excel(data_path+'\\\\'+r, sheet_name = 'prec', usecols = range(0,13))\n",
    "    globals()[meta]=pd.read_excel(data_path+'\\\\'+r, sheet_name = 'meta', usecols = range(0,2))\n",
    "    globals()[mi].index =  globals()[mi]['year']\n",
    "    globals()[ma].index =  globals()[ma]['year']\n",
    "    globals()[prec].index =  globals()[prec]['year']\n",
    "    globals()[mi] = globals()[mi].drop(columns = [\"year\"])\n",
    "    globals()[ma] = globals()[ma].drop(columns = [\"year\"])\n",
    "    globals()[prec] = globals()[prec].drop(columns = [\"year\"])\n",
    "    globals()[ma] = globals()[ma].set_axis(globals()[mi].columns, axis=1, inplace=False)\n",
    "    globals()[s] = pd.concat([globals()[mi], globals()[ma], globals()[prec]], keys=['tmin', 'tmax', 'prec'], axis=1).reorder_levels([1,0],axis=1)\n",
    "    globals()[s] = globals()[s].dropna(how='all')\n",
    "    globals()[s] = globals()[s].rename({'Dez': 'Dec'}, axis=1)\n",
    "    files_ready.append(s)\n",
    "    z+=1\n",
    "    \n",
    "print(files_ready, 'were imported as dataframes.')\n",
    "station_11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b181bc8e",
   "metadata": {},
   "source": [
    "#### We can obtain some first statistics. For example, the average of the minimum temperature measured by station 11 in March was nearly 2 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e319eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_11.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b08bd0",
   "metadata": {},
   "source": [
    "#### Now, we can look at the data graphically: Plot the max temperature for January and October, that was measured by station 360. As we would expect, the maximum temperature in October was always higher than that in January."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc9b34f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(station_360['Jan']['tmax'], label = \"January\")\n",
    "plt.plot(station_360['Oct']['tmax'], label = \"October\")\n",
    "plt.title('Temperature measured by station 360')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Temperature')\n",
    "legend = plt.legend(loc='lower right', shadow=True, fontsize='x-small')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e417af",
   "metadata": {},
   "source": [
    "#### Plot the precipitation for January and June, that was measured by station 360."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dd23c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(station_360['Jan']['prec'], label = \"January\")\n",
    "plt.plot(station_360['Jun']['prec'], label = \"June\")\n",
    "plt.title('Precipitation measured by station 360')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Precipitation')\n",
    "legend = plt.legend(loc='upper right', shadow=True, fontsize='x-small')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fb6fd8",
   "metadata": {},
   "source": [
    "#### We can also plot the temperature with average in December. A slight positive trend in the last 140 years visible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14feccf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "month = 'Dec'\n",
    "fig, ax = plt.subplots()\n",
    "ax.fill_between(station_360[month].index, station_360[month]['tmin'], station_360[month]['tmax'], alpha=.5, linewidth=0, label = \"Min/Max\")\n",
    "ax.plot(station_360[month].index, (station_360[month]['tmin'] + station_360[month]['tmax'])/2, linewidth=2, label = \"Average\")\n",
    "plt.title('Temperature measured by station 360 in '+month)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Temperature')\n",
    "legend = ax.legend(loc='lower right', shadow=True, fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f68b8",
   "metadata": {},
   "source": [
    "#### And plot the minimum temperature of station 557 for two whole years, to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698ae5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(station_557.loc[1950].iloc[:12].values, label = '1950')\n",
    "plt.plot(station_557.loc[2005].iloc[:12].values, label = '2005')\n",
    "plt.title('Min Temperature measured by station 557')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Min Temperature')\n",
    "legend = plt.legend(loc='lower center', shadow=True, fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580a0649",
   "metadata": {},
   "source": [
    "#### At the end, we want to map the weather stations to their regions. By comparing the meta information of each station with the geographical description of a region, we map one weather station to each region (except 'PT' and 'Continente'). The weather data is structured in one dataframe, that has the same format as the production dataframe. This makes computation in later cases easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d16d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.concat([station_546, station_549, station_535, station_170, station_554, station_320, station_522], keys=[\"11\", \"16\", \"17\", \"18\", \"15\", \"2\", \"3\"])\n",
    "weather_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
